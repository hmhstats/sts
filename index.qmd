---
title: "Secondary Traumatic Stress and Teacher Attrition: A Statistical Analysis"
subtitle: "Predicting Teacher Attrition Using Binary Logistic Regression"
author: "Hailee Hawkins (Advisors: Dr. Achraf Cohen and Dr. Melanie DiLoreto)"
date: '`r Sys.Date()`'
format:
  html:
    code-fold: true
    toc: true
    toc-depth: 4
course: Capstone Projects in Data Science
bibliography: references.bib # file contains bibtex for references
#always_allow_html: true # this allows to get PDF with HTML features
self-contained: true
execute: 
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
---

Slides: [slides.html](slides.html){target="_blank"} 

## Introduction

Secondary traumatic stress (STS) is an issue that affects people in many fields of work. This paper focuses on how secondary traumatic stress influences a teacher’s decision to stay in or leave the field of education (attrition). Baird and Kracen say, "Secondary traumatic stress (STS) [@figley1995compassion] [@stamm1995secondary] refers to a syndrome among professional helpers that mimics post-traumatic stress disorder and occurs as a result of exposure to the traumatic experiences of others" [@baird2006vicarious]. Bride explains, "...secondary traumatic stress was operationalized as intrusion, avoidance, and arousal symptoms resulting from indirect exposure to traumatic events by means of a professional helping relationship with a person or persons who have directly experienced traumatic events" [@bride2004development]. These symptoms will be discussed in greater detail later in this paper.

 In schools, teachers can be exposed to traumatic events directly or indirectly. For example, teachers may witness or experience violence such as fights, shootings, physical aggression or other safety threats. They also may learn about students who have experienced trauma through abuse, neglect or violence in their family or community [@inabnett2023secondary]. Teacher’s indirect exposure to trauma may stem from the fact that many students who attend high-needs or Title 1 schools live in poverty. Title 1 is a federal program that provides money to schools with high percentages of children from low-income families [@diaz2017student]. Teachers who work in high-needs schools or Title 1 schools are likely to develop symptoms of secondary traumatic stress due to the experiences of the students they work with. 

Discussions about secondary traumatic stress are relevant for the overall well being of people in service professions, including teachers in high-needs schools. Kidger says, "Our findings show that how teachers feel about their working conditions, that is how stressed or dissatisfied they are, may be linked to poor mental health" [@kidger2016teachers]. Teachers cannot predict when traumatic events will occur for their students or themselves. McEwen and Akil explain, "... if stress related demands continue, then the brain can “get stuck,” ... leading to pathological conditions where external intervention is needed. Examples of such conditions are clinical anxiety or major depression, which may begin with an appropriate response to a stressful event but become maladaptive when they persist and become chronic" [@mcewen2020revisiting]. These findings affirm that secondary traumatic stress affects teachers mentally and physically.

Another reason to discuss secondary traumatic stress is because of its association with attrition. Baker says, "Chronic stress at work, combined with a lack of support and resources, can lead to professional burnout" [@baker2021experience]. Chang says, " ... scholars have adopted the MBI scale developed by Maslach and Jackson [@maslach1981measurement] which measures the psychological syndrome of burnout in three dimensions: emotional exhaustion, cynicism, and inefficacy" [@chang2009appraisal]. De Stasio explains, "Personal burnout is the physical and psychological fatigue and exhaustion experienced by an individual—regardless of their work or occupational status. Work-related burnout is deﬁned as the degree of physical and psychological fatigue and exhaustion perceived by the teacher speciﬁcally in relation to his/her work. Finally, student-related burnout refers to the physical and psychological fatigue and exhaustion that is perceived by the teacher in relation to his/her work with students" [@de2017burnout]. When burnout is experienced in the workplace, it not only affects teachers mentally and physically, but also emotionally. In a study by Hilton, it was found that “The more a teacher feels stressed or disappointed, the more likely they are to leave the profession” [@hilton2021predicting]. These findings confirm that secondary traumatic stress may result in burnout which can lead to teacher attrition.

Secondary traumatic stress can be measured using the Secondary Traumatic Stress Scale (STSS). Bride explains, "... the final version of the STSS is a 17-item, pencil-and-paper, self-report instrument designed to assess the frequency of intrusion, avoidance, and arousal symptoms associated with secondary traumatic stress. Respondents are instructed to read each item and indicate how frequently the item was true for them in the past 7 days using a five-choice, Likert-type response format ranging from 1(never) to 5 (very often). The STSS is comprised of three subscales: Intrusion (items 2, 3, 6, 10, 13), Avoidance (items 1, 5, 7, 9, 12, 14, 17), and Arousal (items 4, 8, 11,15, 16). Scores for the full STSS (all items) and each subscale are obtained by summing the items assigned to each. " [@bride2004development]. Previous research has been done to understand secondary traumatic stress, measure its symptoms and learn how it affects teacher attrition.

In 2023, Inabnett did a study to see if secondary traumatic stress contributes to teacher attrition beyond other known factors, namely teacher self-efficacy and classroom demands. In the study, teachers working in a high-needs school district in Louisiana were surveyed. Several scales - including the Secondary Traumatic Stress Scale (STSS) - were used to measure levels of depression, anxiety and stress, secondary traumatic stress, teacher self-efficacy and classroom resources and demands. The study included 104 participants.

Inabnett found, "Overall, 82 participants reported direct exposure to a traumatic event (77.88%), 88 participants reported indirect exposure to a traumatic event (84.61%), and 76 participants reported direct and indirect exposure to a traumatic event (73.08%). Approximately 23 participants (22.1%) reported it was likely or extremely likely they would leave the teaching profession in the next year; 28 participants (26.9%) reported it was likely or extremely likely they would leave their current school in the next year" [@inabnett2023secondary].

Binary logistic regression models were used to predict if a teacher would leave the profession and if a teacher would leave their current school. For both models, the predictors of teacher attrition were class size, classroom demands, teacher self-efficacy and secondary traumatic stress. In both models, including secondary traumatic stress as a predictor of attrition significantly improved the model’s prediction accuracy. The results of Inabnett’s study showed that secondary traumatic stress was a significant predictor of teacher attrition beyond teacher self-efficacy and classroom resources and demands. 

In 2021, Hilton used the School and Staffing Survey (SASS) and the Teacher Follow Up Survey (TFS) to identify what factors would predict teacher attrition. The 2011-2012 SASS dataset used in the analysis is a nationally representative dataset provided by the National Center for Education Statistics. It includes responses from almost 60,000 private and public school teachers. The researcher limited the sample size to around 4,000 after removing the private school teacher responses due to a low number of responses from private school teachers on the 2012-2013 TFS. The factors studied were teacher autonomy, school climate, student characteristics and a teacher’s general attitudes toward the profession (purpose). Though this study did not directly address secondary traumatic stress as a factor of attrition, the findings may suggest STS as an underlying factor.

For example, the study found that “student apathy toward school has an impact on teacher retention decisions” [@hilton2021predicting]. Students experiencing trauma can become indifferent toward school, and teachers who are experiencing symptoms of secondary traumatic stress may exhaust themselves in attempts to reach these students. This could result in teachers becoming indifferent toward trauma-affected students which is an indication of burnout. Chang mentioned, “When a person feels exhausted or indifferent toward serving or helping people, it is difficult to gain a sense of accomplishment” [@chang2009appraisal]. If a teacher does not feel a sense of accomplishment from their work, and they are experiencing symptoms of secondary traumatic stress and burnout, they may leave their job. Though Hilton’s study does not directly mention this connection, it is possible that secondary traumatic stress could further explain how student apathy leads to teacher attrition. 

Another example of STS as an underlying factor affecting attrition comes from this finding, “Teachers felt that support by administration and support by other teachers was far more important regarding attrition decisions than simply the low salary or inadequate access to resources that come with teaching” [@hilton2021predicting]. New teachers who are not aware of secondary traumatic stress may experience its symptoms and not realize that there is a cause. Hahs-Vaughn and Scherff suggest, "... an induction component to combat stress and foster encouragement among novice teachers is membership in network (i.e., support) groups" [@hahs2008beginning]. Hilton’s findings in 2021 bring attention to how a lack of support from colleagues and administration can lead to teacher attrition even more than low pay and lack of resources. Though Hilton’s study does not directly mention a connection between this finding and secondary traumatic stress, it is possible that newer teachers are leaving the field because they are experiencing symptoms of STS not realizing that it is a phenomenon that can affect all teachers. In these situations, the support of veteran teachers and administrators who have experienced secondary traumatic stress could be a resource that may prevent teacher attrition.  

In an effort to build on the previous research, the current study focuses on predicting teacher attrition in Northwest Florida by using teacher’s responses to the Secondary Traumatic Stress Scale (STSS). The goal of this project is to explain statistically the impact that secondary traumatic stress has on teacher’s decisions to stay in or leave the profession. By analyzing how a teacher’s score for intrusion, avoidance and arousal affects their chance of leaving the profession, the hope is to reveal insight that can inform school administrators and district officials of the likelihood of teacher attrition so proper support and resources can be put in place for teachers. 


## Methods

In this project, binary logistic regression will be used to predict teacher attrition using responses to the Secondary Traumatic Stress Scale (STSS). Peng says “Many educational research problems call for the analysis and prediction of a dichotomous outcome: whether a student will succeed in college, whether a child should be classified as learning disabled (LD), whether a teenager is prone to engage in risky behaviors, and so on” [@peng2002introduction]. Binary logistic regression is useful when the outcome has two categories, such as predicting whether a teacher stays in or leaves the profession.

In binary logistic regression, the dependent (outcome) variable is binary and is modeled using one or more independent (predictor) variables. These predictors can be continuous or categorical. Categorical predictors with two or more levels are typically converted into dummy (indicator) variables, with one category chosen as the reference. The model then compares the effect of other categories relative to this reference. Tranmer explains, "If an explanatory variable has 𝑘 categories, we need 𝑘 − 1 dummy variables to investigate all the differences in the categories with respect to the response variable" [@tranmer2008binary].

In binary logistic regression analysis, the outcome (dependent) variable is typically coded as 0 and 1. An observation coded as 1 usually indicates that the outcome of interest occurred, whereas an observation coded as 0 indicates that it did not occur. As previously mentioned, categorical predictor variables are dummy-coded, where a value of 1 indicates membership in a category, and 0 indicates the reference category [@tranmer2008binary].

The probability of an event occurring given certain predictor variables can be modeled using the logistic regression function:

$$
\pi = P(Y=1 | X_1=x_1, X_2=x_2, \cdots, X_k=x_k)=\frac{1}{1 + e^{-(\beta_0 + \beta_1 x_1 + \beta_2 x_2 + \cdots + \beta_k x_k)}}
$$

In this formula, $\pi$ represents the probability that the outcome variable $Y$ equals 1, given the values of the predictor variables. The variable $Y$ is a binary outcome (dependent) variable, meaning it takes on only two possible values—typically 0 or 1—where 1 usually denotes the occurrence of the event of interest. The terms $X_1, X_2, \ldots, X_k$ are the predictor (independent) variables, and $x_1, x_2, \ldots, x_k$ are their specific observed values. The symbol $e$ denotes Euler’s number (approximately 2.718), which is the base of the natural exponential function. The parameter $\beta_0$ is the intercept of the model, indicating the log-odds of the event occurring when all predictor variables are equal to zero. The coefficients $\beta_1, \beta_2, \ldots, \beta_k$ represent the regression parameters associated with each predictor variable; each $\beta_i$ quantifies the change in the log-odds of the outcome occurring for a one-unit increase in the corresponding predictor variable $X_i$, holding all other variables constant.
[@tranmer2008binary]
[@harris2021primer]
[@peng2002introduction]
[@abdulqader2017applying]

Two-way contingency tables can represent categorical information, facilitating the calculation of odds and odds ratios. Binary logistic regression relies on these concepts for interpretation. Odds compare the probability of an event occurring to the probability of it not occurring, while odds ratios compare the odds of the event between groups.

Binary logistic regression models the logit transformation of the event probability as a linear function of the predictors. The logit (or log-odds) is defined as the natural logarithm of the odds of the event occurring:

$$
logit(\pi)=\ln\left(\frac{\pi}{1 - \pi}\right) = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \cdots + \beta_k x_k
$$

In this formula, $\pi$ is the probability of the event occurring. The expression $\frac{\pi}{1 - \pi}$ represents the odds of the event, defined as the ratio of the probability that the event occurs to the probability that it does not. The term $\text{logit}(\pi)$ refers to the log-odds, or the natural logarithm of the odds. The parameter $\beta_0$ is the intercept, indicating the log-odds of the event when all predictor variables are zero. The terms $\beta_1, \beta_2, \ldots, \beta_k$ are the regression coefficients, where each $\beta_i$ represents the change in the log-odds of the event associated with a one-unit increase in the corresponding predictor variable $x_i$. The variables $x_1, x_2, \ldots, x_k$ are the predictor (independent) variables included in the model.
[@tranmer2008binary]
[@harris2021primer]
[@peng2002introduction]
[@abdulqader2017applying]

Because the model returns log-odds, exponentiating coefficients yields odds ratios, quantifying the change in odds associated with a one-unit increase in a predictor, holding others constant. [@peng2002introduction] For example, an odds ratio of 1.5 indicates a 50% increase in the odds of the event occurring for each one-unit increase in the predictor, holding others constant.

The logistic function mentioned earlier transforms the linear predictor back into a probability bounded between 0 and 1:

$$
\pi=\frac{1}{1 + e^{-(\beta_0 + \beta_1 x_1 + \beta_2 x_2 + \cdots + \beta_k x_k)}}
$$

This expression represents the estimated probability that the event (e.g., teacher attrition) will occur, given specific values of the predictor variables.

Binary logistic regression relies on several assumptions:

1. The dependent variable is binary.
2. Observations are independent of each other.
3. There is no perfect multicollinearity among independent variables.
4. There is a linear relationship between any continuous predictors and the log odds of the outcome.
5. The sample size is sufficiently large, ideally with at least 10 outcome events per predictor variable.

When these assumptions are met, the results of a binary logistic regression analysis can be considered statistically reliable. [@tranmer2008binary] [@harris2021primer] [@abdulqader2017applying]

There are multiple approaches to selecting predictors in a binary logistic regression model. These include using the full model approach, eliminating predictors that are not significantly associated with the outcome based on their p-values, and applying stepwise selection techniques such as forward or backward elimination using criteria like the Akaike Information Criterion (AIC), among others [@shipe2019developing]. After fitting the model, its adequacy can be evaluated using various methods. These include goodness-of-fit tests, likelihood ratio tests, tests of statistical significance for individual predictors, and assessment of predictive performance using classification tables, among other diagnostics [@peng2002introduction] [@abdulqader2017applying].

RStudio will be used to perform the statistical analyses in this project. Several R packages provide functions for performing binary logistic regression and related tasks. These include lmtest, MASS, fastDummies, tidyverse, car, and the base stats package, among others. [@zeileis2002diagnostic] [@venables2013modern] [@kaplan2020fastdummies] [@wickham2019welcome] [@fox2020using] [@team2002r] 

The goal of this project is to predict teacher attrition using responses from the Secondary Traumatic Stress Scale (STSS). Given that teacher attrition is a binary outcome—indicating whether a teacher stays in or leaves the profession—binary logistic regression will be applied in the analysis. Predictor variables will include the subscale scores for intrusion, arousal, and avoidance from the STSS, which will be used to estimate the likelihood of a teacher leaving the profession.

## Analysis and Results

### Data Exploration and Visualization

For this analysis, data were gathered through a questionnaire designed by Dr. Melanie DiLoreto. Following approval from the district superintendent, the instrument was sent to school principals, who then distributed it to their teaching staff via email. Participants were teachers based in Northwest Florida. 

The survey included eight items assessing participants’ experiences with secondary traumatic stress (using items adapted from the [Secondary Traumatic Stress Scale (STSS)](STSS.pdf); [@bride2004development]), compassion fatigue (from the [Professional Quality of Life Scale](ProQOL_5_English.pdf); [@stamm2005professional]), intentions to remain in or leave the teaching profession, and perceptions of whether secondary traumatic stress influenced that decision. For this analysis, only responses to STSS (Item 3) and the participants’ intent to stay or leave teaching (Item 5) were examined.

Teacher attrition was operationalized as any decision to leave face-to-face classroom teaching, including career changes, retirement, or transitions to modalities that substantially reduce direct student interaction. In adapting the STSS for this study, the term “client” was replaced with “student” to better reflect teachers’ experiences, consistent with the scale’s guidance that the term may be substituted to suit the relevant helping relationship.

[View Questionnaire Item 3 (Secondary Traumatic Stress Scale)](Questionnaire Item 3.pdf)

[View Questionnaire Item 5 (Teaching Career Intentions)](Questionnaire Item 5.pdf)

```{r, warning=FALSE, echo=T, message=FALSE}
library(ggplot2)
library(dplyr)
library(corrplot)
library(tidyverse)
library(knitr)
library(ggthemes)
library(ggrepel)
library(dslabs)
library(readr)
library(patchwork)
library(gt)
library(car)
library(tidyr)
library(broom)
library(ResourceSelection)
library(caret)
library(pscl)              
library(pROC)

sts_data <- read_csv("sts_data.csv")



```

A total of 107 teachers responded to the questionnaire. Of these, three participants indicated uncertainty about whether they would continue or leave the teaching profession. Because the analysis required a definitive "yes" or "no" response regarding intent to stay or leave, these uncertain responses were excluded. The final sample included 104 teachers, with 70 indicating they intended to continue teaching and 34 indicating they planned to leave the profession. 

```{r, warning=FALSE, echo=TRUE}
# Recode intent as factor with labels
sts_data <- sts_data %>%
  mutate(leave_label = factor(leave_teaching, levels = c(0, 1), labels = c("Stay", "Leave")))

# Create bar plot with labels
ggplot(sts_data, aes(x = leave_label)) +
  geom_bar(fill = "steelblue") +
  geom_text(stat = "count", aes(label = ..count..), vjust = -0.3, size = 4) +
  labs(
    title = "Teacher Intentions to Leave the Profession",
    x = "Intent",
    y = "Count"
  ) +
  theme_minimal()

```


Density plots were generated to visualize the distribution and spread of scores for each STSS subscale—intrusion, avoidance, arousal—as well as the overall total score for secondary traumatic stress.

The total STSS scores varied widely across participants. Among teachers intending to continue teaching, scores peaked around 30 and 50, while those intending to leave showed a peak around 45. The plot suggests that higher total scores were more frequent among teachers planning to leave the profession.

For intrusion scores, both groups peaked between 11 and 14. Interestingly, scores within this range were slightly more common among teachers intending to stay. However, the plot also indicates that higher intrusion scores were more frequent among those intending to leave.

Avoidance scores peaked around 10 and 20 for teachers planning to stay, whereas teachers intending to leave showed a peak around 17. The distribution suggests that higher avoidance scores were more prevalent among those considering leaving teaching.

Arousal scores peaked around 9 and 12 for teachers intending to stay and around 17 for those intending to leave. Interestingly, the plot indicates that higher arousal scores were slightly more common among teachers intending to continue teaching.


```{r, warning=FALSE, echo=TRUE}
#range for x axis
x_limits <- c(0, 85)  

# Compute max densities manually
max_total <- max(density(sts_data$stss_total_score)$y)
max_intrusion <- max(density(sts_data$intrusion_score)$y)
max_avoidance <- max(density(sts_data$avoidance_score)$y)
max_arousal <- max(density(sts_data$arousal_score)$y)

# Get the global max y for uniform scale
y_max <- max(c(max_total, max_intrusion, max_avoidance, max_arousal))

# Ensure intent is treated as a factor
sts_data$intent_label <- factor(sts_data$leave_teaching, levels = c(0, 1), labels = c("Stay", "Leave"))

# Density plot: Total Score
p_total <- ggplot(sts_data, aes(x = stss_total_score, fill = intent_label)) +
  geom_density(alpha = 0.5) +
  xlim(x_limits) +
  coord_cartesian(ylim = c(0, y_max)) +
  labs(title = "Total STSS Score", x = "Total Score", fill = "Intent") +
  theme_minimal()

# Density plot: Intrusion
p_intrusion <- ggplot(sts_data, aes(x = intrusion_score, fill = intent_label)) +
  geom_density(alpha = 0.5) +
  xlim(x_limits) +
  coord_cartesian(ylim = c(0, y_max)) +
  labs(title = "Intrusion Score", x = "Intrusion", fill = "Intent") +
  theme_minimal()

# Density plot: Avoidance
p_avoidance <- ggplot(sts_data, aes(x = avoidance_score, fill = intent_label)) +
  geom_density(alpha = 0.5) +
  xlim(x_limits) +
  coord_cartesian(ylim = c(0, y_max)) +
  labs(title = "Avoidance Score", x = "Avoidance", fill = "Intent") +
  theme_minimal()

# Density plot: Arousal
p_arousal <- ggplot(sts_data, aes(x = arousal_score, fill = intent_label)) +
  geom_density(alpha = 0.5) +
  xlim(x_limits) +
  coord_cartesian(ylim = c(0, y_max)) +
  labs(title = "Arousal Score", x = "Arousal", fill = "Intent") +
  theme_minimal()

# Combine all 4 plots in a 2x2 layout, share the legend
(p_total | p_intrusion) / (p_avoidance | p_arousal) + 
  plot_layout(guides = "collect") & theme(legend.position = "bottom")
```


The table below presents summary statistics for both groups of teachers. It includes the total STSS score as well as the subscale scores for intrusion, avoidance, and arousal. For each score, the table provides the mean (average), standard deviation (SD), minimum (Min), and maximum (Max) values. 


```{r, warning=FALSE, echo=TRUE}

summary_table <- sts_data %>%
  mutate(Intent = factor(leave_teaching, labels = c("Stay", "Leave"))) %>%
  group_by(Intent) %>%
  summarise(
    Count = n(),
    Total_Mean = mean(stss_total_score, na.rm = TRUE),
    Total_SD = sd(stss_total_score, na.rm = TRUE),
    Total_Min = min(stss_total_score, na.rm = TRUE),
    Total_Max = max(stss_total_score, na.rm = TRUE),
    
    Intrusion_Mean = mean(intrusion_score, na.rm = TRUE),
    Intrusion_SD = sd(intrusion_score, na.rm = TRUE),
    Intrusion_Min = min(intrusion_score, na.rm = TRUE),
    Intrusion_Max = max(intrusion_score, na.rm = TRUE),
    
    Avoidance_Mean = mean(avoidance_score, na.rm = TRUE),
    Avoidance_SD = sd(avoidance_score, na.rm = TRUE),
    Avoidance_Min = min(avoidance_score, na.rm = TRUE),
    Avoidance_Max = max(avoidance_score, na.rm = TRUE),
    
    Arousal_Mean = mean(arousal_score, na.rm = TRUE),
    Arousal_SD = sd(arousal_score, na.rm = TRUE),
    Arousal_Min = min(arousal_score, na.rm = TRUE),
    Arousal_Max = max(arousal_score, na.rm = TRUE)
  )


# Pivot into long format, then wide with groups across top
summary_table_long <- summary_table %>%
  pivot_longer(
    cols = -Intent,                # All columns except the group
    names_to = "Measure",                # Column for "Mean_Total", etc.
    values_to = "Value"
  ) %>%
  pivot_wider(
    names_from = Intent,          # Create one column per group ("Stay", "Leave")
    values_from = Value
  )


kable(summary_table_long, digits = 2, caption = "Summary Statistics (Long Format, Intent Across Columns)")

```


Boxplots were generated to visually compare the distribution of scores across teacher intent groups. A notable outlier was observed in the intrusion scores, where one respondent reported a substantially higher level of intrusion than the rest of the sample. This outlier, with a score of 24 (just below the maximum possible score of 25), belonged to a participant who indicated an intention to remain in the teaching profession (the "stay" group).

```{r, warning=FALSE, echo=TRUE}
# Load required package
library(tidyr)
library(dplyr)
library(ggplot2)

# Convert to long format for easier plotting
sts_long <- sts_data %>%
  mutate(leave_teaching = factor(leave_teaching, levels = c(0, 1), labels = c("Stay", "Leave"))) %>%
  pivot_longer(cols = c(intrusion_score, avoidance_score, arousal_score, stss_total_score),
               names_to = "Subscale",
               values_to = "Score")

# Clean up subscale labels
sts_long$Subscale <- factor(sts_long$Subscale,
                            levels = c("stss_total_score", "intrusion_score", "avoidance_score", "arousal_score"),
                            labels = c("Total STSS", "Intrusion", "Avoidance", "Arousal"))

# Create grouped boxplots
ggplot(sts_long, aes(x = Subscale, y = Score, fill = leave_teaching)) +
  geom_boxplot(position = position_dodge(width = 0.75)) +
  labs(title = "STSS Subscales by Teacher Intent", x = "Subscale", y = "Score", fill = "Intent") +
  theme_minimal() +
  theme(legend.position = "bottom")

```


Before conducting statistical comparisons between the two groups of teachers, tests for normality were performed to assess the distribution of the data.


$$
H_0= \text{The data is normally distributed.}
$$
$$
H_1= \text{The data is not normally distributed.}
$$

```{r, warning=FALSE, echo=TRUE}

# Variables to test
score_vars <- c("stss_total_score", "intrusion_score", "avoidance_score", "arousal_score")

# Initialize results data frame
shapiro_results <- data.frame(
  Variable = character(),
  Group = character(),
  P_Value = numeric(),
  stringsAsFactors = FALSE
)

# Loop through each variable and group to run Shapiro-Wilk test
for (var in score_vars) {
  stay_group <- sts_data[[var]][sts_data$leave_teaching == 0]
  leave_group <- sts_data[[var]][sts_data$leave_teaching == 1]

  stay_test <- shapiro.test(stay_group)
  leave_test <- shapiro.test(leave_group)

  shapiro_results <- rbind(
    shapiro_results,
    data.frame(Variable = var, Group = "Stay", P_Value = stay_test$p.value),
    data.frame(Variable = var, Group = "Leave", P_Value = leave_test$p.value)
  )
}

# Round p-values for display
shapiro_results <- shapiro_results %>%
  mutate(P_Value = round(P_Value, 4))

# Print as a neat table
kable(shapiro_results, caption = "Shapiro-Wilk Test Results for Score Variables by Group")


```


The Shapiro-Wilk tests indicated that for teachers intending to continue teaching, the data for all four STSS subscales deviated from a normal distribution. Specifically, the p-values for the stay group were 0.01536 for STSS Total Score, 0.02752 for Intrusion, 0.008379 for Avoidance, and 0.0349 for Arousal—all below the 0.05 threshold, suggesting violations of the normality assumption. These results are consistent with density plots that visually diverge from the expected bell curve. In contrast, the data for teachers intending to leave teaching met the assumption of normality across all subscales, with p-values of 0.9717 (STSS Total), 0.7114 (Intrusion), 0.3975 (Avoidance), and 0.3525 (Arousal), each well above 0.05. Visual inspection of these distributions further supported normality, with density plots that more closely resemble normal distributions.

```{r, warning=FALSE, echo=TRUE}
# Create labeled version of leave_teaching before reshaping
sts_data <- sts_data %>%
  mutate(
    Teaching_Intent = factor(leave_teaching, levels = c(0, 1), labels = c("Stay", "Leave"))
  )

# Reshape the data to long format
sts_long <- sts_data %>%
  pivot_longer(
    cols = c(stss_total_score, intrusion_score, avoidance_score, arousal_score),
    names_to = "Score_Type",
    values_to = "Score_Value"
  )

# Create density plots for each subscale by teaching intent
ggplot(sts_long, aes(x = Score_Value, fill = Teaching_Intent)) +
  geom_density(alpha = 0.5) +
  facet_grid(Score_Type ~ Teaching_Intent, labeller = labeller(
    Score_Type = c(
      stss_total_score = "Total STSS",
      intrusion_score = "Intrusion",
      avoidance_score = "Avoidance",
      arousal_score = "Arousal"
    )
  )) +
  labs(
    title = "Density Plots of STSS Subscale Scores by Teaching Intent",
    x = "Score",
    y = "Density",
    fill = "Teaching Intent"
  ) +
  theme_minimal()
```


Because the normality assumption was not met for teachers intending to continue teaching, Wilcoxon rank-sum tests were used to compare STSS scores between those planning to stay and those planning to leave the profession.

$$
H_0= \text{The distributions of the two groups are the same.}
$$

$$
H_1= \text{The distributions of the two groups are different.}
$$


```{r, warning=FALSE, echo=TRUE}
scores <- c("stss_total_score", "intrusion_score", "avoidance_score", "arousal_score")

results <- lapply(scores, function(var) {
  test <- wilcox.test(as.formula(paste(var, "~ leave_teaching")), data = sts_data)
  data.frame(
    Score = var,
    W = test$statistic,
    p_value = test$p.value
  )
})

# Combine results into one table

#bind_rows(results)


# Create the results data frame
test_results <- data.frame(
  Subscale = c("STSS Total Score", "Intrusion", "Avoidance", "Arousal"),
  W = c(867.0, 876.5, 885.5, 901.0),
  p_value = c(0.02537618, 0.02951149, 0.03489508, 0.04513017)
)

# Show as table
kable(test_results, digits = 3, caption = "Wilcoxon Rank-Sum Test Results by STSS Subscale")


```


All STSS subscale scores, as well as the total score, showed statistically significant differences between groups. Notably, total STSS scores (W = 867.0, p = 0.025), intrusion scores (W = 876.5, p = 0.030), avoidance scores (W = 885.5, p = 0.035), and arousal scores (W = 901.0, p = 0.045) were significantly higher among teachers intending to leave, suggesting elevated levels of secondary traumatic stress across multiple symptoms.

A correlation matrix was generated to examine the relationships between the STSS subscales and teachers’ attrition responses.

```{r, warning=FALSE, echo=TRUE}

# Add attrition variable (binary) to the matrix
stss_data2 <- sts_data[, c("intrusion_score", "avoidance_score", "arousal_score", "stss_total_score", "leave_teaching")]

# Correlation matrix (Pearson)
cor_matrix <- cor(stss_data2, use = "complete.obs")

# Visualize
library(corrplot)
corrplot(cor_matrix, method = "number", type = "upper", tl.col = "black", number.cex = 0.8)

```

Pearson correlation coefficients indicated strong to very strong positive associations among the STSS subscales. For instance, intrusion was strongly correlated with avoidance (r = 0.80) and arousal (r = 0.84). Avoidance and arousal were also highly correlated (r = 0.88). Each subscale showed very strong correlations with the total STSS score (r = 0.91–0.96), indicating a high degree of internal consistency within the scale.

In contrast, correlations between the STSS scores and intent to leave teaching were weak (r = 0.18–0.22), suggesting that while higher levels of secondary traumatic stress may be associated with a greater likelihood of considering attrition, the strength of this relationship is modest.

### Modeling and Results

For the purposes of analysis, responses to Questionnaire Item 3 were recoded to reflect only the numerical values on the Likert scale (1 = Never, 2 = Rarely, 3 = Occasionally, 4 = Often, 5 = Very Often). Since Item 3 encompassed the items from the Secondary Traumatic Stress Scale (STSS), these responses were used to calculate subscale scores for Intrusion, Avoidance, and Arousal, as well as a total STSS score. Specifically, the Intrusion subscale score was calculated by summing the responses to items 2, 3, 6, 10, and 13. The Avoidance subscale score included items 1, 5, 7, 9, 12, 14, and 17. The Arousal subscale was based on items 4, 8, 11, 15, and 16. The total STSS score was obtained by summing all 17 items [@bride2004development].

Data from Questionnaire Item 5 were recoded into a binary variable to indicate whether respondents intended to leave or remain in the teaching profession. Responses were coded as 1 if the respondent indicated they would be leaving teaching—specifically, if they selected Retire (2), Leave the teaching profession (3), or Become an administrator (4). Responses were coded as 0 if the respondent indicated they would Continue teaching (1).

Five respondents selected Other (5). Of these, one stated they would continue teaching because they felt "stuck in the profession"; this response was recoded as 0. Another respondent indicated a move to online teaching. Given the study’s focus on daily, face-to-face student interaction as a key contributor to secondary traumatic stress, this response was recoded as 1, since the respondent would no longer be in direct contact with students. The remaining three respondents selected "Other" and expressed uncertainty about whether they would remain in or leave the profession. Because binary logistic regression requires a dichotomous outcome, these three cases were excluded from the analysis. 


#### Model 1

A binary logistic regression analysis was conducted to determine whether scores on the Secondary Traumatic Stress Scale (STSS) could predict teachers’ intentions to leave the profession. The first model included the total STSS score as the sole predictor of teacher attrition.

$$ 
\ln(\text{attrition}) = -2.1175 + 0.0317(\text{Total STSS Score}) 
$$

```{r, warning=FALSE, echo=TRUE}
# Model 1: Logistic regression with total STSS score
model1 <- glm(leave_teaching ~ stss_total_score, data = sts_data, family = binomial)


# View model summary (coefficients, p-values, etc.)
summary(model1)


# Tidy the model output, exponentiate to get odds ratios
model1_table <- tidy(model1, conf.int = TRUE, exponentiate = TRUE) %>%
  select(term, estimate, conf.low, conf.high, p.value) %>%
  rename(
    Term = term,
    Odds_Ratio = estimate,
    CI_Lower = conf.low,
    CI_Upper = conf.high,
    P_Value = p.value
  ) %>%
  mutate(across(c(Odds_Ratio, CI_Lower, CI_Upper, P_Value), ~ round(., 4)))

# Create the table
kable(
  model1_table,
  caption = "Model 1: Odds Ratios, 95% Confidence Intervals, and p-values for STSS Total Score"
)
```

The model was statistically significant, χ²(1, N = 104) = 4.94, p = .030, indicating that total STSS scores significantly predicted attrition intention. The odds of indicating an intention to leave teaching increased by 3.2% for each additional point on the STSS (OR = 1.03, 95% CI [1.00, 1.06]).

#### Model 2

A second binary logistic regression model was conducted to examine whether the three components of secondary traumatic stress—Intrusion, Avoidance, and Arousal—significantly predicted teachers’ intentions to leave the profession. This model used the subscale scores for each component as separate predictor variables to assess their individual contributions to teacher attrition. 

$$ 
\ln(\text{attrition}) = -2.1066 + 0.0922(\text{Intrusion Score}) + 0.0684(\text{Avoidance Score}) - 0.0724(\text{Arousal Score})
$$

```{r, warning=FALSE, echo=TRUE}
# Model 2: Logistic regression with STSS subscale scores
model2 <- glm(leave_teaching ~ intrusion_score + avoidance_score + arousal_score, data = sts_data, family = binomial)

# View model summary
summary(model2)

p_value <- 1 - pchisq(5.93, df = 3)
print(p_value)  # This will print approximately 0.115


# Tidy and exponentiate results
model2_table <- tidy(model2, conf.int = TRUE, exponentiate = TRUE) %>%
  select(term, estimate, conf.low, conf.high, p.value) %>%
  rename(
    Term = term,
    Odds_Ratio = estimate,
    CI_Lower = conf.low,
    CI_Upper = conf.high,
    P_Value = p.value
  ) %>%
  mutate(across(c(Odds_Ratio, CI_Lower, CI_Upper, P_Value), ~ round(., 4)))

# Display the table
kable(
  model2_table,
  caption = "Model 2: Odds Ratios, 95% Confidence Intervals, and p-values for STSS Subscale Scores"
)
```

The overall model did not reach statistical significance in predicting attrition intentions, χ²(3, N = 104) = 5.93, p = .115, indicating that these subscale scores together did not significantly improve prediction over the null model.

Individually, none of the subscales were statistically significant predictors of attrition intentions: intrusion (OR = 1.10, 95% CI [0.91, 1.32], p = .322), avoidance (OR = 1.07, 95% CI [0.94, 1.23], p = .324), and arousal (OR = 0.93, 95% CI [0.75, 1.15], p = .504). This suggests that, when considered simultaneously, higher scores on these subscales were not associated with significantly greater or lower odds of intending to leave teaching.

Model 2 was not statistically significant, likely due to multicollinearity among the STSS subscales. As indicated by the exploratory analysis, the subscales were highly correlated. To further assess multicollinearity, the Variance Inflation Factor (VIF) was calculated for each predictor variable.

```{r, warning=FALSE, echo=TRUE}

# Run the model 2 vif
vif_values <- vif(model2)

# Convert to data frame for better display
vif_table <- data.frame(
  Variable = names(vif_values),
  VIF = round(as.numeric(vif_values), 2)
)

# Print the table
kable(vif_table, caption = "Variance Inflation Factor (VIF) Table")
```


VIF values above 3 confirmed moderate to high multicollinearity, which may have masked individual predictor effects.

Since Model 2, which included all three subscale scores (Intrusion, Avoidance, and Arousal) as predictors, was not statistically significant, separate binary logistic regression analyses were conducted to examine whether each component of secondary traumatic stress individually predicted teachers’ intentions to leave the profession.

#### Model 3

Model 3 assessed the predictive value of the Intrusion subscale score on teachers’ intentions to leave the profession.

$$ 
\ln(\text{attrition}) = -2.1044 + 0.1091(\text{Intrusion Score}) 
$$


```{r, warning=FALSE, echo=TRUE}
# Model with intrusion only
model_intrusion <- glm(leave_teaching ~ intrusion_score, data = sts_data, family = binomial)
summary(model_intrusion)
# Tidy and exponentiate results
model_intrusion_table <- tidy(model_intrusion, conf.int = TRUE, exponentiate = TRUE) %>%
  select(term, estimate, conf.low, conf.high, p.value) %>%
  rename(
    Term = term,
    Odds_Ratio = estimate,
    CI_Lower = conf.low,
    CI_Upper = conf.high,
    P_Value = p.value
  ) %>%
  mutate(across(c(Odds_Ratio, CI_Lower, CI_Upper, P_Value), ~ round(., 4)))

# Display the table
kable(
  model_intrusion_table,
  caption = "Model (Intrusion Only): Odds Ratios, 95% Confidence Intervals, and p-values"
)
```

Intrusion was a significant predictor of attrition intentions, χ²(1, N = 104) = 4.94, p = .031. For every one-point increase in intrusion scores, the odds of intending to leave teaching increased by approximately 11% (OR = 1.11, 95% CI [1.01, 1.23]).

#### Model 4

Model 4 used the Avoidance subscale score to predict teachers’ intentions to leave the profession.

$$ 
\ln(\text{attrition}) = -1.9626 + 0.0704(\text{Avoidance Score}) 
$$

```{r, warning=FALSE, echo=TRUE}

# Model with avoidance only
model_avoidance <- glm(leave_teaching ~ avoidance_score, data = sts_data, family = binomial)
summary(model_avoidance)

# Tidy and exponentiate results
model_avoidance_table <- tidy(model_avoidance, conf.int = TRUE, exponentiate = TRUE) %>%
  select(term, estimate, conf.low, conf.high, p.value) %>%
  rename(
    Term = term,
    Odds_Ratio = estimate,
    CI_Lower = conf.low,
    CI_Upper = conf.high,
    P_Value = p.value
  ) %>%
  mutate(across(c(Odds_Ratio, CI_Lower, CI_Upper, P_Value), ~ round(., 4)))

# Display the table
kable(
  model_avoidance_table,
  caption = "Model (Avoidance Only): Odds Ratios, 95% Confidence Intervals, and p-values"
)
```

Avoidance also significantly predicted attrition intentions, χ²(1, N = 104) = 4.95, p = .030. For every one-point increase in avoidance scores, the odds of intending to leave increased by about 7% (OR = 1.07, 95% CI [1.01, 1.14]).

#### Model 5

Model 5 examined whether the Arousal subscale score predicted teachers’ intentions to leave the profession.

$$ 
\ln(\text{attrition}) = -1.8426 + 0.0820(\text{Arousal Score}) 
$$

```{r, warning=FALSE, echo=TRUE}
# Model with arousal only
model_arousal <- glm(leave_teaching ~ arousal_score, data = sts_data, family = binomial)
summary(model_arousal)
# Tidy and exponentiate results
model_arousal_table <- tidy(model_arousal, conf.int = TRUE, exponentiate = TRUE) %>%
  select(term, estimate, conf.low, conf.high, p.value) %>%
  rename(
    Term = term,
    Odds_Ratio = estimate,
    CI_Lower = conf.low,
    CI_Upper = conf.high,
    P_Value = p.value
  ) %>%
  mutate(across(c(Odds_Ratio, CI_Lower, CI_Upper, P_Value), ~ round(., 4)))

# Display the table
kable(
  model_arousal_table,
  caption = "Model (Arousal Only): Odds Ratios, 95% Confidence Intervals, and p-values"
)
```

Arousal showed a trend towards significance, χ²(1, N = 104) = 3.27, p = .071. Higher arousal scores were associated with increased odds of intending to leave teaching, but this effect did not reach conventional levels of statistical significance (OR = 1.09, 95% CI [0.99, 1.18]).


#### Model Comparison and Diagnostics

Only the total score, intrusion, and avoidance models showed statistically significant results. The model with all three subscales combined did not reach significance, likely due to overlap between the subscales. Arousal, by itself, showed a possible trend but wasn’t strong enough to be considered significant.

```{r, warning=FALSE, echo=TRUE}


# Tidy each model and exponentiate to get odds ratios
tidy_model1 <- tidy(model1, conf.int = TRUE, exponentiate = TRUE) %>%
  mutate(Model = "Model 1", AIC = AIC(model1))

tidy_model3 <- tidy(model_intrusion, conf.int = TRUE, exponentiate = TRUE) %>%
  mutate(Model = "Model 3", AIC = AIC(model_intrusion))

tidy_model4 <- tidy(model_avoidance, conf.int = TRUE, exponentiate = TRUE) %>%
  mutate(Model = "Model 4", AIC = AIC(model_avoidance))

# Combine all models
combined_models <- bind_rows(tidy_model1, tidy_model3, tidy_model4)

# Filter out intercepts, rename, and capitalize predictor names
model_table <- combined_models %>%
  filter(term != "(Intercept)") %>%
  select(Model, term, estimate, std.error, conf.low, conf.high, p.value, AIC) %>%
  rename(
    Predictor = term,
    `Odds Ratio` = estimate,
    `Std. Error` = std.error,
    `CI Lower` = conf.low,
    `CI Upper` = conf.high,
    `p-value` = p.value
  ) %>%
  mutate(
    Predictor = case_when(
      Predictor == "stss_total_score" ~ "STSS Total Score",
      Predictor == "intrusion_score" ~ "Intrusion Score",
      Predictor == "avoidance_score" ~ "Avoidance Score",
      TRUE ~ Predictor
    )
  ) %>%
  arrange(Model)

# Display the table
kable(model_table, digits = 3, caption = "Comparison of Logistic Regression Models Predicting Teacher Attrition")

```

Both Model 1 (total secondary traumatic stress score) and Model 3 (intrusion subscale) fit the data equally well in predicting teacher attrition intentions, each yielding the lowest AIC values. Model 4 (avoidance subscale) also performed well and was statistically significant, indicating that avoidance symptoms are relevant to attrition decisions. However, its slightly higher AIC and the comparatively stronger association between intrusion scores and attrition suggest that Model 3 offers a more informative and efficient predictor. As such, the focus of further analysis and interpretation is placed on Models 1 and 3.

To ensure the validity of the logistic regression analyses, the linearity assumption between continuous predictors and the log odds of the outcome was assessed for both Model 1 (total secondary traumatic stress score) and Model 3 (intrusion subscale). Predicted probabilities from each model were transformed into log odds and plotted against their respective predictors. Visual inspection of these plots verified that the linearity assumption was adequately met for both models.

```{r}
# Set plotting area to 1 row, 2 columns (side by side)
par(mfrow = c(1, 2))

# Model 1: STSS Total Score
sts_data$pred_prob_model1 <- predict(model1, type = "response")
sts_data$log_odds_model1 <- log(sts_data$pred_prob_model1 / (1 - sts_data$pred_prob_model1))

plot(sts_data$stss_total_score, sts_data$log_odds_model1,
     xlab = "STSS Total Score",
     ylab = "Log Odds of Leaving Teaching",
     main = "Linearity Check for Model 1")

# Model 3: Intrusion Score
sts_data$pred_prob_model3 <- predict(model_intrusion, type = "response")
sts_data$log_odds_model3 <- log(sts_data$pred_prob_model3 / (1 - sts_data$pred_prob_model3))

plot(sts_data$intrusion_score, sts_data$log_odds_model3,
     xlab = "Intrusion Score",
     ylab = "Log Odds of Leaving Teaching",
     main = "Linearity Check for Model 3")

# Reset plotting area back to default
par(mfrow = c(1, 1))

```

Since Model 1 and Model 3 had the lowest and identical AIC values, additional diagnostic tests were conducted to evaluate their fit and predictive performance. These included the Hosmer-Lemeshow goodness-of-fit test, likelihood ratio test, assessment of the significance of individual predictors, and classification metrics such as accuracy, sensitivity, and specificity. To further assess model quality, McFadden’s Pseudo-R² was calculated to estimate explained variance, and the area under the ROC curve (AUC) was used to evaluate each model’s ability to discriminate between teachers who indicated intent to leave and those who did not.


```{r, warning=FALSE, echo=TRUE}
models <- list(
  Model1 = model1,
  Model3 = model_intrusion
)

results <- lapply(models, function(mod) {
  # Hosmer-Lemeshow Test
  hl <- hoslem.test(mod$y, fitted(mod))
  
  # Null model for LRT
  null_mod <- glm(leave_teaching ~ 1, family = binomial, data = sts_data)
  lrt <- anova(null_mod, mod, test = "Chisq")
  
  # Predictions and confusion matrix
  pred_probs <- predict(mod, type = "response")
  pred_class <- ifelse(pred_probs > 0.5, 1, 0)
  cm <- confusionMatrix(factor(pred_class), factor(sts_data$leave_teaching))
  
  # Pseudo R² (McFadden)
  pseudo_r2 <- pR2(mod)["McFadden"]
  
  # AUC
  roc_obj <- roc(sts_data$leave_teaching, pred_probs)
  auc_value <- auc(roc_obj)
  
  list(
    HosmerLemeshow_p = hl$p.value,
    LRT_p = lrt$`Pr(>Chi)`[2],
    Accuracy = cm$overall["Accuracy"],
    Sensitivity = cm$byClass["Sensitivity"],
    Specificity = cm$byClass["Specificity"],
    Pseudo_R2 = pseudo_r2,
    AUC = auc_value
  )
})



```

$$
\text{Hosmer-Lemeshow (HL) Test}
$$

$$
H_0:
\text{The logistic regression model fits the data well.}
$$

$$
H_1:
\text{The model does not fit the data well.}
$$

Both Model 1 (total STSS score) and Model 3 (intrusion score) demonstrated good overall fit based on the Hosmer-Lemeshow test (Model 1: p = .605; Model 3: p = .336), indicating no significant lack of fit.

$$
\text{Likelihood Ratio Test}
$$
$$
H_0:
\text{The simpler model (with no predictors) fits the data as well as the more complex model.}
$$
$$
H_1:
\text{The more complex model (with predictors) fits the data significantly better than the simpler model.}
$$

Likelihood ratio tests showed that both models significantly improved prediction over a null model with no predictors (Model 1: p = .026; Model 3: p = .026).

$$
\text{Accuracy, Sensitivity and Specificity}
$$

In terms of classification accuracy, Model 3 slightly outperformed Model 1 (68.3% vs. 67.3%), primarily due to a marginally higher sensitivity (ability to correctly identify teachers intending to leave). Both models showed low specificity (~11.8%), indicating limited ability to correctly identify those intending to stay.

$$
\text{McFadden's Pseudo-}R^{2}
$$
In terms of overall model fit, both models yielded identical McFadden’s Pseudo-R² values of 0.038, indicating a modest improvement over a model with no predictors. While Pseudo-R² does not reflect the exact proportion of variance explained, these values suggest that total STSS score and intrusion score each contribute meaningfully, though moderately, to predicting teachers’ intent to leave the profession.


$$
\text{Area Under the ROC Curve (AUC)} 
$$
In terms of discriminative ability, both models demonstrated modest performance based on the area under the ROC curve (AUC). Model 1 achieved an AUC of 0.636, while Model 3 scored slightly lower at 0.632. These values indicate that both models are somewhat better than chance at distinguishing between teachers who intend to leave and those who do not, but their ability to do so is limited.

```{r}
# Create a data frame with results
diagnostic_summary <- data.frame(
  Model = c("Model1", "Model3"),
  HosmerLemeshow_p = c(0.6050059, 0.3359190),
  LRT_p = c(0.02619078, 0.02625793),
  Accuracy = c(0.6730769, 0.6826923),
  Sensitivity = c(0.9428571, 0.9571429),
  Specificity = c(0.1176471, 0.1176471),
  Pseudo_R2 = c(0.03760612, 0.03757245),
  AUC = c(0.6357143, 0.6317227)
)

# Print a clean table with 3 decimal places
kable(diagnostic_summary, digits = 3, caption = "Model Diagnostic Summary")

```



#### Practical Interpretation of Model Outputs 

To further interpret the practical implications of the logistic regression models, predicted probabilities of attrition were calculated using representative values from the sample: the low (10th percentile), average (mean), and high (90th percentile) scores. Specifically, the regression equations for each model were used to estimate the likelihood that a teacher with a low, average, or high STSS Total Score or Intrusion Score would indicate an intention to leave the profession. These predicted probabilities were then compared to the actual attrition rate observed in the dataset (32.7%), providing a real-world frame of reference for the model outputs across the spectrum of scores.


```{r, warning=FALSE, echo=TRUE}
# Define percentiles for low and high
low_pct <- 0.10
high_pct <- 0.90

# Calculate values for STSS total score
low_total <- quantile(sts_data$stss_total_score, probs = low_pct, na.rm = TRUE)
mean_total <- mean(sts_data$stss_total_score, na.rm = TRUE)
high_total <- quantile(sts_data$stss_total_score, probs = high_pct, na.rm = TRUE)

# Model 1 coefficients
beta0_total <- -2.1175
beta1_total <- 0.0317

# Function to get predicted probability
pred_prob <- function(x, intercept, slope) {
  log_odds <- intercept + slope * x
  1 / (1 + exp(-log_odds))
}

# Predicted probabilities for Model 1 (STSS total score)
prob_low_total <- pred_prob(low_total, beta0_total, beta1_total)
prob_mean_total <- pred_prob(mean_total, beta0_total, beta1_total)
prob_high_total <- pred_prob(high_total, beta0_total, beta1_total)

# Print results
cat("Model 1 (STSS Total Score) Predicted Probabilities:\n")
cat(sprintf("  Low (10th percentile = %.2f): %.3f\n", low_total, prob_low_total))
cat(sprintf("  Average (mean = %.2f): %.3f\n", mean_total, prob_mean_total))
cat(sprintf("  High (90th percentile = %.2f): %.3f\n\n", high_total, prob_high_total))

# Calculate values for intrusion score
low_intrusion <- quantile(sts_data$intrusion_score, probs = low_pct, na.rm = TRUE)
mean_intrusion <- mean(sts_data$intrusion_score, na.rm = TRUE)
high_intrusion <- quantile(sts_data$intrusion_score, probs = high_pct, na.rm = TRUE)

# Model 3 coefficients
beta0_intrusion <- -2.1044
beta1_intrusion <- 0.1091

# Predicted probabilities for Model 3 (Intrusion Score)
prob_low_intrusion <- pred_prob(low_intrusion, beta0_intrusion, beta1_intrusion)
prob_mean_intrusion <- pred_prob(mean_intrusion, beta0_intrusion, beta1_intrusion)
prob_high_intrusion <- pred_prob(high_intrusion, beta0_intrusion, beta1_intrusion)

# Print results
cat("Model 3 (Intrusion Score) Predicted Probabilities:\n")
cat(sprintf("  Low (10th percentile = %.2f): %.3f\n", low_intrusion, prob_low_intrusion))
cat(sprintf("  Average (mean = %.2f): %.3f\n", mean_intrusion, prob_mean_intrusion))
cat(sprintf("  High (90th percentile = %.2f): %.3f\n\n", high_intrusion, prob_high_intrusion))

# Create a data frame to summarize results
results_df <- data.frame(
  Model = rep(c("STSS Total Score", "Intrusion Score"), each = 3),
  Score_Level = rep(c("Low (10th percentile)", "Average (mean)", "High (90th percentile)"), 2),
  Score_Value = c(low_total, mean_total, high_total, low_intrusion, mean_intrusion, high_intrusion),
  Predicted_Probability = c(prob_low_total, prob_mean_total, prob_high_total, prob_low_intrusion, prob_mean_intrusion, prob_high_intrusion)
)

# Format output for better readability
kable(results_df, digits = 3, caption = "Predicted Probabilities of Attrition at Low, Average, and High Score Levels")

```

In the logistic regression models, a teacher’s predicted probability of indicating intent to leave varies meaningfully across the range of scores. For Model 1 (STSS Total Score), predicted probabilities range from approximately 20.1% at the low 10th percentile score (23.30), to 31.9% at the average score (42.83), and 46.8% at the high 90th percentile score (62.80). Similarly, for Model 3 (Intrusion Score), predicted probabilities range from about 20.7% at the low 10th percentile score (7.00), to 31.9% at the average score (12.36), and 45.7% at the high 90th percentile score (17.70). The average predicted probabilities closely match the observed attrition rate of 32.7% in our sample, highlighting how higher scores are associated with substantially increased likelihood of attrition.

```{r, warning=FALSE, echo=TRUE}

# Create data frame with sequence of values for STSS total score
stss_seq <- seq(min(sts_data$stss_total_score, na.rm = TRUE),
                max(sts_data$stss_total_score, na.rm = TRUE), length.out = 100)

# Calculate predicted probabilities for each value
prob_stss <- pred_prob(stss_seq, beta0_total, beta1_total)

df_stss <- data.frame(score = stss_seq, probability = prob_stss, model = "STSS Total Score")

# Same for Intrusion score
intrusion_seq <- seq(min(sts_data$intrusion_score, na.rm = TRUE),
                     max(sts_data$intrusion_score, na.rm = TRUE), length.out = 100)

prob_intrusion <- pred_prob(intrusion_seq, beta0_intrusion, beta1_intrusion)

df_intrusion <- data.frame(score = intrusion_seq, probability = prob_intrusion, model = "Intrusion Score")

# Combine data frames
df_plot <- rbind(df_stss, df_intrusion)

#Plot
ggplot(df_plot, aes(x = score, y = probability, color = model)) +
  geom_line(linewidth = 1.2) +          # changed size to linewidth here
  labs(
    x = "Score",
    y = "Predicted Probability of Attrition",
    title = "Predicted Probability of Attrition Across Score Range",
    color = "Model"
  ) +
  theme_minimal() +
  theme(text = element_text(size = 14))

```

This figure visually represents how higher STSS Total Scores and higher Intrusion Scores correspond to an increased probability of teachers indicating intent to leave the profession. As scores rise across their observed ranges, the predicted likelihood of attrition increases substantially in both models. This visualization depicts the progressive increase in attrition risk captured by the models and underscores the importance of these stress-related measures in predicting teacher attrition.


### Conclusion

The primary goal of this analysis was to identify a model that effectively predicts teacher attrition. Results indicated that Models 1 and 3 were strong candidates. Both models demonstrated the lowest AIC values and high sensitivity (~95%) in correctly identifying teachers who intended to leave the profession.

#### Key Findings

Model 1 used the overall STSS score to predict whether a teacher intended to leave or continue teaching.

$$ 
\ln(\text{attrition}) = -2.1175 + 0.0317(\text{Total STSS Score}) 
$$

This model indicates that for every one-point increase in a teacher’s total STSS score, the likelihood of leaving the profession increases by approximately 3%. For a teacher with a score near the sample average of 43, the predicted probability of attrition is around 32%.

Model 3 used the intrusion score to predict whether a teacher intended to leave or continue teaching.

$$ 
\ln(\text{attrition}) = -2.1044 + 0.1091(\text{Intrusion Score}) 
$$

This model indicates that for every one-point increase in a teacher’s intrusion score, the likelihood of leaving the profession increases by approximately 11%. A teacher scoring near the sample average of 12 has an estimated 32% probability of leaving the teaching profession.

Model 4 used the avoidance score to predict whether a teacher intended to leave or continue teaching. 

$$ 
\ln(\text{attrition}) = -1.9626 + 0.0704(\text{Avoidance Score}) 
$$

This model was statistically significant, indicating that for every 1 point increase in a teacher's avoidance score, the odds of leaving teaching increase by about 7%. However, for practical interpretation and clarity, the focus remained on Models 1 and 3.

Both models 1 and 3 demonstrated high sensitivity—around 95%—indicating strong ability to identify teachers who intend to leave. However, specificity was low, with only about 12% of teachers who intended to stay correctly classified. While overall accuracy approached 70%, the models’ ability to distinguish between leavers and stayers across all thresholds was modest, with AUC values around 0.63.

The models improved predictability by approximately 4% over a model with no predictors, as reflected in McFadden’s Pseudo-R² values of 0.038. While Pseudo-R² does not indicate the exact proportion of variance explained, these results suggest that total STSS score and intrusion score contribute meaningfully—though moderately—to predicting teachers’ intent to leave the profession.

#### Implications 

The results of this analysis provide clear evidence that secondary traumatic stress (STS) can significantly impact teachers’ well-being in ways that influence their decision to remain in or leave the profession. Higher overall STS scores—and specifically higher scores on the intrusion subscale—were associated with an increased likelihood of teacher attrition. These findings have important implications for school districts serving trauma-exposed student populations, particularly in high-needs schools, where teachers may be at elevated risk for STS-related burnout and turnover.

This analysis revealed that intrusion symptoms were the strongest indicators of teacher attrition, compared to arousal and avoidance symptoms. The intrusion subscale of the [Secondary Traumatic Stress Scale](STSS.pdf) includes items 2, 3, 6, 10, and 13, which reflect the physical, mental, and emotional disturbances teachers may experience as a result of direct or indirect exposure to student trauma. These symptoms often intensify with repeated exposure [@mcewen2020revisiting], highlighting how cumulative stress can contribute to a teacher’s decision to leave the profession.

While these findings indicate that intrusion symptoms are the strongest predictors of teacher attrition, this does not diminish the significance of arousal and avoidance symptoms. Both of these symptom categories also impact teachers’ physical, mental, and emotional well-being. Their effects may extend beyond professional consequences—such as burnout and attrition—and contribute to negative outcomes in teachers’ personal lives as well.

It is imperative that teachers not only receive training on trauma and its effects on students, but also on how exposure to student trauma can impact their own well-being. As Inabnett noted, “Many teachers do not receive education on trauma and trauma-informed practices in their teacher preparation programs” [@inabnett2023secondary]. Without adequate preparation—particularly for those entering high-needs schools—teacher attrition related to secondary traumatic stress is likely to persist. Teachers need to be made aware that STS is a real and common phenomenon they may encounter due to the environments they work in and the students they serve.

Administrators and district leaders have a critical opportunity to mitigate—if not prevent—the effects of secondary traumatic stress (STS) on teachers. As Nguyen suggests, “In particular, educators and policy-makers should consider creating school environments where strong administrative support, consistent teacher collaborations, and regular and meaningful professional development could provide young or specialty teachers the resources and support needed to keep them in teaching” [@nguyen2019factors]. Offering professional development focused on recognizing signs of trauma in students, as well as identifying and addressing STS in educators, would greatly enhance awareness and provide practical tools to support teacher well-being and retention.

Such training and support could also provide teachers with practical strategies for coping with stress. For example, it may open opportunities for teachers to connect with school counselors or on-site mental health professionals. Teachers who develop strategies to view students’ behaviors more objectively tend to report a greater sense of personal accomplishment and reduced burnout, which may, in turn, help buffer against the effects of secondary traumatic stress [@chang2009appraisal]. Additionally, creating space and time for teachers to connect in supportive peer communities—particularly with more experienced colleagues—could offer another valuable avenue for guidance, reflection, and emotional support.
 
The results of this analysis highlight secondary traumatic stress (STS) as a significant factor influencing teacher attrition. STS not only impacts the well-being of educators, but also affects student achievement when capable and committed teachers leave the profession as a result of its effects. While the problem is complex, it is not insurmountable—meaningful action can and should be taken to address teacher attrition related to STS.

#### Suggestions For Further Study

The models developed in this analysis demonstrated reasonable predictive performance based solely on secondary traumatic stress (STS) total and subscale scores. However, their accuracy and utility could be significantly enhanced by incorporating additional demographic and professional variables, such as sex, age, years of teaching experience, subject taught, and other relevant factors. Future research should focus on improving model specificity to better identify teachers likely to remain in the profession. This may involve exploring alternative classification thresholds, integrating additional predictors, or examining interaction effects to enhance the models’ discriminative capabilities. Additionally, including variables related to teacher demographics and school context could improve the explanatory power of the models by offering a more comprehensive understanding of the factors contributing to teacher attrition.

## References
